{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5d6198",
   "metadata": {},
   "source": [
    "<h2 style = \"color:darkblue\"> Movie Recommendation System </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0f69b",
   "metadata": {},
   "source": [
    "There are several machine learning models that you can consider for building a movie recommendation system. The choice of model depends on the type of recommendation system you're aiming to create. Here are a few popular options:\n",
    "\n",
    "1. **Collaborative Filtering Models:**\n",
    "   - User-Based Collaborative Filtering: This model recommends movies to a user based on the preferences of users with similar tastes. It calculates similarity scores between users.\n",
    "   - Item-Based Collaborative Filtering: This model recommends movies by finding similar movies to those the user has already watched or rated. It calculates similarity scores between movies.\n",
    "\n",
    "\n",
    "2. **Content-Based Models:**\n",
    "   - Content-Based Filtering: This model recommends movies based on the features of movies that the user has shown interest in. It focuses on movie attributes like genre, cast, and plot.\n",
    "\n",
    "\n",
    "3. **Matrix Factorization Models:**\n",
    "   - SVD (Singular Value Decomposition): This model decomposes the user-movie interaction matrix to identify latent features. It's used to fill in missing values (ratings) and make recommendations.\n",
    "\n",
    "\n",
    "4. **Hybrid Models:**\n",
    "   - Hybrid Recommender: This combines multiple recommendation techniques (e.g., collaborative filtering and content-based) to provide more accurate and diverse recommendations.\n",
    "\n",
    "\n",
    "5. **Deep Learning Models:**\n",
    "   - Neural Collaborative Filtering: This deep learning model combines collaborative and content-based approaches using neural networks.\n",
    "\n",
    "\n",
    "6. **Ensemble Models:**\n",
    "   - Ensemble Recommenders: Ensemble techniques combine predictions from multiple models to improve recommendation quality.\n",
    "\n",
    "Remember that the choice of model depends on factors such as the available data, your specific goals, and the trade-offs between accuracy, interpretability, and scalability. It's often beneficial to experiment with different models and evaluate their performance using metrics like precision, recall, or Mean Average Precision (MAP) to determine the best fit for your recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9ddf6",
   "metadata": {},
   "source": [
    "- Adding Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# ast.literal_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a3fa5",
   "metadata": {},
   "source": [
    "- Reading Files : 'Movies' & 'Credits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "credits = pd.read_csv(\"tmdb_5000_credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01245e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies.columns\n",
    "# credits.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69a799",
   "metadata": {},
   "source": [
    "<h3 style=\"color:darkblue\"> Data preprocessing </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ef994",
   "metadata": {},
   "source": [
    "- Merging the two dataframe 'Movies' and 'Credits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231af696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_movie = movies.merge(credits,on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac09cc",
   "metadata": {},
   "source": [
    "Building a movie recommendation system using machine learning involves selecting appropriate features to capture user preferences and movie characteristics. Here are some feature variables you might consider for your recommendation model:\n",
    "\n",
    "1. **User Preferences:** User ID,Ratings,Watch History,Genre Preferences,Release Year Preferences\n",
    "\n",
    "\n",
    "2. **Movie Characteristics:** Movie ID,Genre, Release Year, Director, Cast, Keywords,Average Rating,Popularity\n",
    "   \n",
    "   \n",
    "3. **Textual Features:** Movie Plot Summary, Movie Tags\n",
    "\n",
    "\n",
    "4. **Collaborative Filtering Features:** Similarity Metrics, User-based or Item-based Collaborative Filtering\n",
    "\n",
    "\n",
    "5. **Contextual Features:** Time of Day, Location\n",
    "\n",
    "\n",
    "6. **External Data:** IMDb or TMDb Data: External data from movie databases can provide additional information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf8189",
   "metadata": {},
   "source": [
    "- Dropping Columns based on the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71159ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie = df_movie[['movie_id','title','overview','genres', 'keywords','cast','crew']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02b55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicate records\n",
    "df_movie.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75aa978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates records\n",
    "df_movie.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get values from key:'names' \n",
    "def convert(obj):\n",
    "    l_list = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        l_list.append(i[\"name\"])\n",
    "    return l_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d24f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_movie['genres'] = df_movie['genres'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie['keywords'] = df_movie['keywords'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fun to extract first three names from the key values\n",
    "def convert3(obj):\n",
    "    l_list = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            l_list.append(i[\"name\"])\n",
    "            counter+=1\n",
    "        else:\n",
    "            break\n",
    "    return l_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie['cast'] = df_movie['cast'].apply(convert3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84aa329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie['cast'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ast.literal_eval(df_movie['crew'][1])\n",
    "# var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67933d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function to fetch the director \n",
    "def director(obj):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job'] == 'Director':\n",
    "            l.append(i['name'])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie['Director'] = df_movie['crew'].apply(director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the 'crew' column\n",
    "df_movie.drop(columns='crew',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca843515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting overview column into list\n",
    "df_movie['overview'] = df_movie['overview'].apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda2355",
   "metadata": {},
   "source": [
    "- Removing Spaces in order to create precise Tags for Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie['overview'].apply(lambda x :[i.replace(' ','') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie['genres'].apply(lambda x :[i.replace(' ','') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_movie = ['overview', 'genres', 'keywords', 'cast','Director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7489e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns_movie:\n",
    "    df_movie[i] = df_movie[i].apply(lambda x :[val.replace(' ','') for val in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a tag\n",
    "df_movie['tags'] = df_movie['overview'] + df_movie['genres'] + df_movie['keywords'] + df_movie['cast'] + df_movie['Director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movie = df_movie[['movie_id','title','tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting tags into string\n",
    "data_movie['tags'] = data_movie['tags'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d6369d",
   "metadata": {},
   "source": [
    "The \"Bag of Words\" (BoW) concept is a fundamental technique in Natural Language Processing (NLP) and machine learning that represents text data as a collection of individual words or tokens, disregarding grammar and word order. It's a simplified representation that transforms text into a numerical format suitable for machine learning algorithms. The name \"Bag of Words\" implies that we're treating text as an unordered collection, similar to a bag where words are tossed in without considering their sequence.\n",
    "\n",
    "*Explanation of the Bag of Words concept along with examples:*\n",
    "\n",
    "**Process of Creating a Bag of Words:**\n",
    "\n",
    "1. **Tokenization:** Break the text into individual words or tokens. Punctuation and capitalization are usually removed, and the text is split into words.\n",
    "\n",
    "2. **Vocabulary Creation:** Create a unique vocabulary of all the distinct words in the entire corpus (collection of documents). Each word is assigned a unique index.\n",
    "\n",
    "3. **Document Representation:** For each document in the corpus, create a vector where each dimension corresponds to a word in the vocabulary. The value in each dimension represents the frequency of that word in the document.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Consider the following two sentences:\n",
    "1. \"The cat in the hat.\"\n",
    "2. \"The dog in the yard.\"\n",
    "\n",
    "**Step 1: Tokenization:**\n",
    "- Sentence 1 tokens: [\"the\", \"cat\", \"in\", \"the\", \"hat\"]\n",
    "- Sentence 2 tokens: [\"the\", \"dog\", \"in\", \"the\", \"yard\"]\n",
    "\n",
    "**Step 2: Vocabulary Creation:**\n",
    "The unique words in the corpus are: [\"the\", \"cat\", \"in\", \"hat\", \"dog\", \"yard\"]\n",
    "\n",
    "**Step 3: Document Representation:**\n",
    "Create vectors for each sentence based on the vocabulary. The vectors indicate the frequency of each word in the sentence.\n",
    "\n",
    "- Sentence 1 vector: [2, 1, 1, 1, 0, 0]\n",
    "- Sentence 2 vector: [2, 0, 1, 0, 1, 1]\n",
    "\n",
    "In this representation, the order of words is disregarded, and only the frequency of words matters. The \"bag\" nature of this representation means that it's as if we have a bag containing the words, and we're looking at the counts of each word.\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "Bag of Words is used for various NLP tasks, including:\n",
    "- Text classification: Determining the category of a document (spam/ham, sentiment analysis, topic classification).\n",
    "- Document clustering: Grouping similar documents together.\n",
    "- Information retrieval: Ranking documents based on their relevance to a query.\n",
    "- Keyword extraction: Identifying the most important words in a document.\n",
    "\n",
    "While Bag of Words is a simple representation, it has limitations, such as not considering word order or capturing the semantics of language. Advanced techniques like TF-IDF (Term Frequency-Inverse Document Frequency) and word embeddings address some of these limitations by incorporating more context and meaning into the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting tags into lowercase\n",
    "data_movie['tags'] = data_movie['tags'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9732bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de138565",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(data_movie['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in cv.get_feature_names_out()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea5e20",
   "metadata": {},
   "source": [
    "**Stemming** is a text normalization technique in natural language processing (NLP) that involves reducing words to their base or root form, called a \"stem.\" The purpose of stemming is to simplify words to their core form so that different variations of the same word are treated as the same, making it easier to perform analysis, comparisons, and information retrieval.\n",
    "\n",
    "- Stemming involves removing prefixes, suffixes, and other affixes from words to produce the root form. The resulting stem may not always be a valid word, but it represents the core meaning of the word.\n",
    "\n",
    "- For example, consider the words \"running,\" \"runner,\" and \"runs.\" Applying stemming, we would convert all of these to the stem \"run.\"\n",
    "\n",
    "- Stemming algorithms vary in complexity and rules, but they generally work by applying linguistic rules to the words. Some common stemming algorithms include the Porter stemming algorithm and the Snowball stemming algorithm.\n",
    "\n",
    "**Example:**\n",
    "Let's take a few words and apply stemming using the Porter stemming algorithm:\n",
    "\n",
    "- Original Word: \"running\"\n",
    "  - Stemmed Word: \"run\"\n",
    "\n",
    "- Original Word: \"jumps\"\n",
    "  - Stemmed Word: \"jump\"\n",
    "\n",
    "- Original Word: \"happily\"\n",
    "  - Stemmed Word: \"happili\" (Note: The stem might not be a valid word, but it represents the root meaning.)\n",
    "\n",
    "In situations where maintaining semantic accuracy is critical, more advanced techniques like *lemmatization* are preferred. Lemmatization considers the context and meaning of words to produce a valid base form, known as the \"lemma.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad382346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    list_val = []\n",
    "    for i in text.split(' '):\n",
    "        list_val.append(ps.stem(i))\n",
    "        \n",
    "    return \" \".join(list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movie['tags'] = data_movie['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-create the vector\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000,stop_words='english')\n",
    "\n",
    "vectors = cv.fit_transform(data_movie['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e45739",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in cv.get_feature_names_out()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d54a681",
   "metadata": {},
   "source": [
    "- Euclidean distance tends to be ineffective in text analysis due to text data's high-dimensional nature, variation in text length, irrelevant dimensions, and sparsity. In contrast, cosine similarity is well-suited for text analysis because it normalizes for vector magnitudes, considers vector orientation, handles sparsity, and is resilient to high-dimensional spaces. Cosine similarity's characteristics make it a preferred choice for measuring similarity between text documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e95f2e4",
   "metadata": {},
   "source": [
    "- **Calculating Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(enumerate(similarity[0]),reverse=True,key=lambda x:x[1])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    movie_index = data_movie[data_movie['title']==movie].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    movies_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]\n",
    "    \n",
    "    for i in movies_list:\n",
    "        print(data_movie.iloc[i[0]].title)\n",
    "#         print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeee773",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend('Avatar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e37e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_movie,open('movies.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc15394",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_movie.to_dict(),open('movies_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similarity,open('similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a07e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
